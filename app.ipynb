{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain.docstore.document import Document as LangDocument\n",
    "from rag import * \n",
    "from prompt import *\n",
    "import autogen\n",
    "\n",
    "MASTER_JS = r\".\\MG0900S.js\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立RAG\n",
    "# all_chunks = collect_all_vb_chunks(SOURCE_DIR)\n",
    "# build_vector_store(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b428793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassification(BaseModel):\n",
    "    line: str = Field(...)\n",
    "    original: str = Field(...)\n",
    "    issue: str = Field(...)\n",
    "    replacement: str = Field(...)\n",
    "    reason: str = Field(...)\n",
    "\n",
    "# Json 輸出格式解析器\n",
    "parser = JsonOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# 使用本地 LLM 模型\n",
    "embed_model = OllamaEmbeddings(model=\"nomic-embed-text\") \n",
    "fst_llm = ChatOllama(model=\"llama3:8B\") #提出\n",
    "sec_llm = ChatOllama(model=\"mistral:7B\") #審查\n",
    "third_llm = ChatOllama(model=\"phi3:3.8B\") #檢查改動是否符合原始邏輯，若符合則發動投票\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from json_repair import repair_json\n",
    "# 建立工具\n",
    "def extract_json(text: str) -> str:\n",
    "    try:\n",
    "        start = text.find('[')\n",
    "        end = text.rfind(']') + 1\n",
    "        if start == -1 or end <= start:\n",
    "            return \"No JSON array found.\"\n",
    "        json_str = text[start:end]\n",
    "        json_str = json_str.encode('utf-8').decode('unicode_escape')\n",
    "        repaired_string = repair_json(json_str)\n",
    "        try:\n",
    "            parsed = json.loads(repaired_string)\n",
    "        except json.JSONDecodeError:\n",
    "            cleaned = re.sub(r',\\s*([\\]}])', r'\\1', repaired_string)\n",
    "            repaired_string = repair_json(cleaned)\n",
    "            parsed = json.loads(repaired_string)\n",
    "        return json.dumps(parsed, ensure_ascii=False, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to extract JSON: {str(e)}\"\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"check json format\",\n",
    "        func=extract_json,\n",
    "        description=\"Use this tool when you receive a string that may contain a JSON array and you need to extract or validate it.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ff2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 Agent\n",
    "agent_llama3_8B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=fst_llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_mistral_7B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=sec_llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_phi3_3dot8B = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=third_llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6363db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 生成.js\n",
    "def write_modified_js(original_path: str, original_code: str, approved_changes: List[dict]):\n",
    "    modified_code = original_code\n",
    "    for item in approved_changes:\n",
    "        modified_code = modified_code.replace(item[\"original\"], item[\"replacement\"])\n",
    "    \n",
    "    p = Path(original_path)\n",
    "    output_path = p.with_name(f\"{p.stem}_modified{p.suffix}\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(modified_code)\n",
    "\n",
    "# 呼叫LLM\n",
    "def call_llm(llm, prompt):\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if hasattr(response, \"content\") else str(response) # Ensure it's a string\n",
    "\n",
    "\n",
    "# ====== decoder ======\n",
    "def read_text_file_safely(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw_data = f.read()\n",
    "        detected = chardet.detect(raw_data)\n",
    "        encoding = detected[\"encoding\"] or \"utf-8\"\n",
    "\n",
    "    fallback_encodings = []\n",
    "\n",
    "    if encoding: # Add the detected encoding first\n",
    "        fallback_encodings.append(encoding)\n",
    "    if 'GB2312' not in fallback_encodings: # Add GB2312 if not already present\n",
    "        fallback_encodings.append(\"GB2312\")\n",
    "\n",
    "    # Ensure common encodings are covered\n",
    "    additional_encodings = [\"utf-8\", \"big5\", \"cp950\", \"gbk\", \"gb18030\", \"utf-16\", \"windows-1252\"]\n",
    "    for enc in additional_encodings:\n",
    "        if enc not in fallback_encodings:\n",
    "            fallback_encodings.append(enc)\n",
    "\n",
    "    for enc in fallback_encodings:\n",
    "        try:\n",
    "            print(f\"嘗試使用編碼decode: {enc}\")\n",
    "            return raw_data.decode(enc)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    raise UnicodeDecodeError(f\"所有常見編碼皆無法解碼檔案: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1420a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Main LLM Logic ======\n",
    "def code_rewrite_proposal(code: str) -> str:\n",
    "    # Agent 1：提案改寫\n",
    "    fst_input = fst_prompt.format(code=code)\n",
    "    # fst_response = call_llm(fst_llm, fst_input)\n",
    "    # 改成agent with tool\n",
    "    fst_response = agent_llama3_8B.run(fst_input)\n",
    "    print(fst_response)\n",
    "    return fst_response\n",
    "    # proposals = extract_json(fst_response)\n",
    "\n",
    "    # if not proposals:\n",
    "    #     return {\"status\": \"no-change\", \"original\": code}\n",
    "\n",
    "    # approved_results = []\n",
    "\n",
    "    # for i, p in enumerate(proposals):\n",
    "    #     print(f\"\\nProcessing proposal {i+1}: {p}\")\n",
    "    #     # 檢查關鍵鍵是否存在\n",
    "    #     if not all(k in p for k in [\"line\", \"original\", \"issue\", \"replacement\", \"reason\"]):\n",
    "    #         print(f\"Skipping proposal {i+1} due to missing required keys: {p}\")\n",
    "    #         continue\n",
    "\n",
    "    #     # Agent 2：語法審查\n",
    "    #     sec_input = sec_prompt.format(proposal=json.dumps([p], ensure_ascii=False))\n",
    "    #     # sec_response = call_llm(sec_llm, sec_input)\n",
    "    #     sec_response = agent_mistral_7B.run(sec_input)\n",
    "    #     sec_result = extract_json(sec_response)\n",
    "    #     print(\"sec_result:\", sec_result)\n",
    "        \n",
    "\n",
    "    #     # Agent 3：語意一致性\n",
    "    #     third_input = third_prompt.format(\n",
    "    #         original=p[\"original\"],\n",
    "    #         rewritten=p[\"replacement\"]\n",
    "    #     )\n",
    "    #     # third_response = call_llm(third_llm, third_input)\n",
    "    #     third_response = agent_phi3_3dot8B.run(third_input)\n",
    "    #     third_result = extract_json(third_response)\n",
    "    #     print(\"third_result:\", third_result)\n",
    "\n",
    "    #     # 投票機制\n",
    "    #     vote = (\n",
    "    #         (sec_result and sec_result[0][\"vote\"] == \"approve\")\n",
    "    #         and (third_result and third_result[0][\"vote\"] == \"approve\")\n",
    "    #     )\n",
    "\n",
    "    #     if vote:\n",
    "    #         approved_results.append(p)\n",
    "\n",
    "    # return {\"status\": \"done\", \"approved\": approved_results}\n",
    "\n",
    "def code_linting_report(proposals: str) -> List:\n",
    "    if not proposals:\n",
    "        return [{\"status\": \"no-change\", \"message\": \"\"}]\n",
    "    \n",
    "    try:\n",
    "        proposals_list = json.loads(proposals)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Invalid JSON input: {e}\")\n",
    "        return [{\"status\": \"invalid-json\", \"message\": str(e)}]\n",
    "    \n",
    "    sec_response_list = []\n",
    "\n",
    "    for i, p in enumerate(proposals_list):\n",
    "        print(f\"\\nProcessing proposal {i+1}: {p}\")\n",
    "        # 檢查關鍵鍵是否存在\n",
    "        if not all(k in p for k in [\"line\", \"original\", \"issue\", \"replacement\", \"reason\"]):\n",
    "            print(f\"Skipping proposal {i+1} due to missing required keys: {p}\")\n",
    "            continue\n",
    "\n",
    "        sec_input = sec_prompt.format(proposal=json.dumps([p], ensure_ascii=False))\n",
    "        sec_response = agent_mistral_7B.run(sec_input)\n",
    "        print(sec_response)\n",
    "        sec_response_list.append(sec_response)\n",
    "\n",
    "    return sec_response_list\n",
    "\n",
    "def extract_function_blocks(js_code: str) -> list[str]:\n",
    "    blocks = []\n",
    "    stack = []\n",
    "    start = None\n",
    "    i = 0\n",
    "    while i < len(js_code):\n",
    "        if js_code[i:i+8].startswith('function'):\n",
    "            if not stack:\n",
    "                start = i\n",
    "        if js_code[i] == '{':\n",
    "            stack.append(i)\n",
    "        elif js_code[i] == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack and start is not None:\n",
    "                    blocks.append(js_code[start:i+1].strip())\n",
    "                    start = None\n",
    "        i += 1\n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 單一個js FOR測試\n",
    "def run_first_js_review(folder_path: str):\n",
    "    \n",
    "    code = read_text_file_safely(folder_path)\n",
    "    # function_div = extract_function_blocks(code)\n",
    "\n",
    "    \n",
    "    proposal_str = code_rewrite_proposal(code)\n",
    "\n",
    "    print(f\"proposal_str\", proposal_str)\n",
    "\n",
    "    linting_str = code_linting_report(proposal_str)\n",
    "    \n",
    "    print(f\"linting_str\", linting_str)\n",
    "\n",
    "\n",
    "    # if result[\"status\"] == \"done\":\n",
    "    #     print(f\"修改完畢如下\")\n",
    "    #     print(result[\"approved\"])\n",
    "    # else:\n",
    "    #     print(f\"無需修改\")\n",
    "\n",
    "run_first_js_review(MASTER_JS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61d877",
   "metadata": {},
   "source": [
    "### Able to improve ###\n",
    "\n",
    "1. 提示工程: few-shot、many-shot 的內容收斂到單一項目(e.g document.all)\n",
    "2. 提示工程: Chain-of-Thought、Buffer of Thought\n",
    "3. 提示工程: 更精確的提示詞、role-playing\n",
    "\n",
    "目前是使用LLMs Ensemble 中類似 Role-based Multi-Agent 架構(但不是真的Agnet)，所以這個方向有:\n",
    "\n",
    "4. Agent: 根據文章 https://arxiv.org/pdf/2304.03442 建立架構，記錄成功的記憶(memory)\n",
    "5. Agnet: MCP https://ihower.tw/presentation/ihower-MCP-2025-05-23.pdf?fbclid=IwQ0xDSwKfVtdleHRuA2FlbQIxMQABHpHnLaqK2X9AmlPvZO0bxqlCfWfCa3UUJV6VEPKdkzzqOsKRLHGSClKi7bV0_aem_HBd1VtOjMNWnJVOLBG0L6Q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
