{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json\n",
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import chardet\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain.docstore.document import Document as LangDocument\n",
    "\n",
    "MASTER_JS = r\"C:\\users\\tuf\\documents\\cloudysys_nickfury\\dcmsln\\dcmsln_201812\\Master\\PageJS\\Query\"\n",
    "BUSINESSRULE_DIR = r\"C:\\Users\\TUF\\Documents\\cloudysys_nickfury\\dcmsln\\BusinessRule\\Commons\"\n",
    "VECTOR_STORE_PATH = \"./common/vectorstore\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG function\n",
    "def remove_simplified_chinese(text: str) -> str:\n",
    "    return re.sub(r\"[^\\x00-\\x7F\\u4e00-\\u9fff\\n\\r\\t\\w\\s.,:;!?(){}[\\]\\\"'@#$%^&*\\-+=\\\\/]\", \"\", text)\n",
    "\n",
    "def read_file_with_detected_encoding(file_path: str) -> str:\n",
    "    print(file_path)\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw = f.read()\n",
    "    return raw.decode('GB2312', errors='ignore')\n",
    "\n",
    "def extract_vb_functions(file_path: str) -> List[LangDocument]:\n",
    "    raw_code = read_file_with_detected_encoding(file_path)\n",
    "\n",
    "    # 移除簡體中文註解\n",
    "    cleaned_code = remove_simplified_chinese(raw_code)\n",
    "\n",
    "    pattern = r\"(Public\\s+(Sub|Function)|Private\\s+(Sub|Function)|Sub|Function)\\s+\\w+\\s*\\(.*?\\)[\\s\\S]+?End\\s+(Sub|Function)\"\n",
    "    matches = re.finditer(pattern, cleaned_code, re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    docs = []\n",
    "    file_name = Path(file_path).name\n",
    "\n",
    "    for match in matches:\n",
    "        full_func = match.group(0).strip()\n",
    "\n",
    "        # 擷取函式名稱\n",
    "        func_name_match = re.search(r\"(Sub|Function)\\s+(\\w+)\", full_func)\n",
    "        func_name = func_name_match.group(2) if func_name_match else \"unknown\"\n",
    "\n",
    "        doc = LangDocument(\n",
    "            page_content=full_func,\n",
    "            metadata={\n",
    "                \"source\": file_name,\n",
    "                \"function\": func_name\n",
    "            }\n",
    "        )\n",
    "        docs.append(doc)\n",
    "\n",
    "    return docs\n",
    "def collect_all_vb_chunks(directory: str) -> List[LangDocument]:\n",
    "    all_docs = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".vb\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                chunks = extract_vb_functions(file_path)\n",
    "                all_docs.extend(chunks)\n",
    "    return all_docs\n",
    "\n",
    "def build_vector_store(docs: List[LangDocument]):\n",
    "    print(f\"[info] Building vectorstore with {len(docs)} code chunks...\")\n",
    "    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    os.makedirs(VECTOR_STORE_PATH, exist_ok=True)\n",
    "    db.save_local(VECTOR_STORE_PATH)\n",
    "    print(f\"[success] Vectorstore saved to: {VECTOR_STORE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立RAG\n",
    "# all_chunks = collect_all_vb_chunks(SOURCE_DIR)\n",
    "# build_vector_store(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b428793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassification(BaseModel):\n",
    "    line: int = Field(...)\n",
    "    original: str = Field(...)\n",
    "    issue: str = Field(...)\n",
    "    replacement: str = Field(...)\n",
    "    reason: str = Field(...)\n",
    "\n",
    "# Json 輸出格式解析器\n",
    "parser = JsonOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# 使用本地 LLM 模型\n",
    "embed_model = OllamaEmbeddings(model=\"nomic-embed-text\") \n",
    "fst_llm = ChatOllama(model=\"llama3:8B\") #提出\n",
    "sec_llm = ChatOllama(model=\"mistral:7B\") #審查\n",
    "third_llm = ChatOllama(model=\"phi3:3.8B\") #檢查改動是否符合原始邏輯，若符合則發動投票\n",
    "\n",
    "fst_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a JavaScript expert whose job is to refactor outdated or deprecated syntax into modern, browser-compatible JavaScript.\n",
    "\n",
    "Let's carefully analyze the provided JavaScript code snippet. Step by step, identify any lines that use deprecated or non-recommended patterns. For each problematic line, explain why it is an issue, and suggest an improved modern alternative.\n",
    "\n",
    "=== Original Code ===\n",
    "{code}\n",
    "===\n",
    "\n",
    "Think step by step. Then return your output in **valid JSON format** (double quotes only), suitable for machine parsing. (if there are no issues, return an empty array):\n",
    "**All values must be wrapped in double quotes as string**\n",
    "**All values except last one must has common in the end**\n",
    "                                          \n",
    "[\n",
    "  {{\n",
    "    \"line\": \"<line number where the issue occurs>\",\n",
    "    \"original\": \"<original line of code>\",\n",
    "    \"issue\": \"<description of the issue>\",\n",
    "    \"replacement\": \"<modernized line of code>\",\n",
    "    \"reason\": \"<explanation of why this change is needed>\"\n",
    "  }}\n",
    "]\n",
    "\"\"\")\n",
    "\n",
    "sec_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert in JavaScript Linter tools.\n",
    "\n",
    "Carefully review the following proposed code modifications described in JSON format.  \n",
    "For each item, think step-by-step about the following:\n",
    "\n",
    "1. **Syntax Validity** – Is the proposed replacement syntactically correct?\n",
    "2. **Modern Browser Compatibility** – Is the suggested code aligned with current JavaScript standards and compatible with modern browsers?\n",
    "3. **Practical Feasibility** – Would this change work reliably in real-world JavaScript environments?\n",
    "\n",
    "Take your time to reason through each point before making your decision.\n",
    "\n",
    "=== Proposal ===\n",
    "{proposal}\n",
    "===\n",
    "\n",
    "Please return a JSON array. Each item should include your judgment and reasoning in the following format:\n",
    "[\n",
    "  {{\n",
    "    \"line\": <line number of the proposal>,\n",
    "    \"vote\": \"approve\" | \"reject\",\n",
    "    \"comment\": \"<Step-by-step explanation of your reasoning and conclusion>\"\n",
    "  }}\n",
    "]\n",
    "\"\"\")\n",
    "\n",
    "third_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert in semantic consistency analysis.\n",
    "\n",
    "Your task is to compare the original JavaScript code with its rewritten version and determine whether the rewritten code preserves the same logic and functionality.\n",
    "\n",
    "Follow these steps in your reasoning:\n",
    "1. Identify the purpose and behavior of the original code.\n",
    "2. Analyze the rewritten code line by line to understand its logic.\n",
    "3. Compare both implementations for semantic equivalence.\n",
    "4. Look for any missing functionality, altered logic, or behavior changes.\n",
    "\n",
    "=== Original Code ===\n",
    "{original}\n",
    "\n",
    "=== Rewritten Code ===\n",
    "{rewritten}\n",
    "\n",
    "Based on your analysis, return a JSON object in the following format:\n",
    "{\n",
    "  \"consistency\": \"high\" | \"medium\" | \"low\",\n",
    "  \"comment\": \"<Does the rewritten code preserve the original intent? Are there any discrepancies or omissions?>\"\n",
    "}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6363db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成.js\n",
    "def write_modified_js(original_path: str, original_code: str, approved_changes: List[dict]):\n",
    "    modified_code = original_code\n",
    "    for item in approved_changes:\n",
    "        modified_code = modified_code.replace(item[\"original\"], item[\"replacement\"])\n",
    "    \n",
    "    p = Path(original_path)\n",
    "    output_path = p.with_name(f\"{p.stem}_modified{p.suffix}\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(modified_code)\n",
    "\n",
    "# 審核json\n",
    "def extract_json(text: str) -> list:\n",
    "    try:\n",
    "        # 找第一個 \"[\" 與最後一個 \"]\"\n",
    "        start = text.find('[')\n",
    "        end = text.rfind(']') + 1\n",
    "\n",
    "        if start == -1 or end <= start:\n",
    "            print(\"找不到 JSON 陣列\")\n",
    "            return []\n",
    "\n",
    "        json_str = text[start:end]\n",
    "        json_str = json_str.encode('utf-8').decode('unicode_escape')\n",
    "\n",
    "        # 嘗試修剪\n",
    "        json_str = re.sub(r',\\s*}', '}', json_str)\n",
    "        json_str = re.sub(r',\\s*]', ']', json_str)\n",
    "\n",
    "        print(\"json陣列:\", json_str)\n",
    "\n",
    "        return json.loads(json_str)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\nJSON 解析失敗：{e}\")\n",
    "        print(\"原始輸出：\", text)\n",
    "        return []\n",
    "\n",
    "# 呼叫LLM\n",
    "def call_llm(llm, prompt):\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if hasattr(response, \"content\") else response\n",
    "\n",
    "# ====== Main LLM Logic ======\n",
    "def analyze_message_with_multi_llm(code: str):\n",
    "    # Agent 1：提案改寫\n",
    "    fst_input = fst_prompt.format(code=code)\n",
    "    fst_response = call_llm(fst_llm, fst_input)\n",
    "    proposals = extract_json(fst_response)\n",
    "\n",
    "    # 印出反饋\n",
    "    print(\"fst_output:\", proposals)\n",
    "\n",
    "    if not proposals:\n",
    "        return {\"status\": \"no-change\", \"original\": code}\n",
    "\n",
    "    approved_results = []\n",
    "\n",
    "    for p in proposals:\n",
    "        # Agent 2：語法審查\n",
    "        sec_input = sec_prompt.format(proposal=json.dumps([p], ensure_ascii=False))\n",
    "        sec_result = extract_json(call_llm(sec_llm, sec_input))\n",
    "        # 印出反饋\n",
    "        print(\"sec_result:\", sec_result)\n",
    "        \n",
    "\n",
    "        # Agent 3：語意一致性\n",
    "        third_input = third_prompt.format(\n",
    "            original=p[\"original\"],\n",
    "            rewritten=p[\"replacement\"]\n",
    "        )\n",
    "        third_result = extract_json(call_llm(third_llm, third_input))\n",
    "        # 印出反饋\n",
    "        print(\"third_result:\", third_result)\n",
    "\n",
    "        # 投票機制整合\n",
    "        vote = (\n",
    "            (sec_result and sec_result[0][\"vote\"] == \"approve\")\n",
    "            and (third_result and third_result[\"consistency\"] in [\"high\", \"medium\"])\n",
    "        )\n",
    "\n",
    "        if vote:\n",
    "            approved_results.append(p)\n",
    "\n",
    "    return {\"status\": \"done\", \"approved\": approved_results}\n",
    "\n",
    "# ====== Folder Runner ======\n",
    "\n",
    "def run_folder_review(folder_path: str):\n",
    "    js_files = list(Path(folder_path).rglob(\"*.js\"))\n",
    "    print(f\"共發現 {len(js_files)} 個 JS 檔案\")\n",
    "\n",
    "    for file_path in js_files:\n",
    "        print(f\"\\n 分析：{file_path}\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            code = f.read()\n",
    "\n",
    "        result = analyze_message_with_multi_llm(code)\n",
    "\n",
    "        if result[\"status\"] == \"done\":\n",
    "            write_modified_js(file_path, result[\"original\"], result[\"approved\"])\n",
    "        else:\n",
    "            print(f\"無需修改：{file_path}\")\n",
    "\n",
    "# 單一個js FOR測試\n",
    "def run_first_js_review(folder_path: str):\n",
    "    js_files = list(Path(folder_path).rglob(\"*.js\"))\n",
    "    if not js_files:\n",
    "        print(\"找不到任何 JS 檔案\")\n",
    "        return\n",
    "\n",
    "    first_file = js_files[0]\n",
    "    print(f\"正在分析第一個 JS 檔案：{first_file}\")\n",
    "\n",
    "    with open(first_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    result = analyze_message_with_multi_llm(code)\n",
    "\n",
    "    if result[\"status\"] == \"done\":\n",
    "        write_modified_js(first_file, result[\"original\"], result[\"approved\"])\n",
    "    else:\n",
    "        print(f\"無需修改：{first_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_first_js_review(MASTER_JS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
